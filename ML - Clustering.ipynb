{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 3 Clustering Problems\n",
    "\n",
    "In clustering we are dealing with problems of unsupervised learning. Aka problems in which we do not know what we are going to determine."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3.1 K-Means\n",
    "We have a set of data but we do not know whether there are clusters of data. K-means doe precisely that, finds clusters from raw unorganised data.\n",
    "\n",
    "The algorithm works as follows\n",
    "\n",
    "1- choose a number of clusters for the dataset\n",
    "\n",
    "2- select k points at random $\\rightarrow$ centroids (not necessarly in my dataset)\n",
    "\n",
    "3- assign each data point to the closest centroid $\\rightarrow$ formation of K-clusters\n",
    "\n",
    "4- Update the position of the centroids\n",
    "\n",
    "5- reassign each point to the closest centroid and go to 4 $\\rightarrow$ if no new assignement $\\rightarrow$ END.\n",
    "\n",
    "Questions: How do we update the position of the centroids? HOw do we decide how many clusters are there in our dataset?\n",
    "\n",
    "The update of the centroids is done by computing the center of mass of each cluster (assigning identical mass to each point in the cluster) an placin the centroid there.\n",
    "\n",
    "In order to decide the number of clusters that go into our classification, we need to define a metric or use in order to understand what is the correct number of clusters. We use the WCSS defined as\n",
    "\n",
    "$$\n",
    "\\text{WCSS} = \\sum_{j} \\Big( \\sum_{p_i \\in C_j} d(p_i, C_j)^2 \\Big)\n",
    "$$\n",
    "\n",
    "where $C_j$ is the j-th centroid and $p_i$ is the i-th point. We want to decrease WCSS, but theoretically WCSS dminishes as we increase the number of clusters and if $C = p$ $\\text{WCSS}\\rightarrow 0$. We want to find some form of converegence that stops the number of clusters from increasing. We can plot the values of the WCSS as a function of the number of clusters and individuate the point of convergence $\\rightarrow$ elbow method.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn; seaborn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================Import a dataset\n",
    "dataset = pd.read_csv('Part 4 - Clustering/Section 24 - K-Means Clustering/Mall_Customers.csv') #name of the dataset\n",
    "X = dataset.iloc[:, :-1].values \n",
    "y = dataset.iloc[:, -1].values #modify extrems if necessary\n",
    "\n",
    "# we want to understand and identify the behaviour of the set of customers according to the features reported into the dataset. We create a dependent variable and we assign that to the elements of the dataset according to the features. \n",
    "\n",
    "#yolooooo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}