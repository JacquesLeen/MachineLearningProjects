{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# 6 - REINFORCEMENT LEARNING"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn; seaborn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Part 6 - Reinforcement Learning/Section 32 - Upper Confidence Bound (UCB)/Ads_CTR_Optimisation.csv') #name of the dataset\n",
    "\n",
    "# the data set here is a simulation -> each row represents a user and the 1s in the row are the ads on which the user WOULD click. We want to determine as fast as possible the ads with the best ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation of the UCB algorithm\n",
    "import math\n",
    "num_of_slection = [0]*d #intialize a list of 10 0s\n",
    "sums_of_rewards = [0]*d\n",
    "avg_reward = 0\n",
    "tot_reward = 0\n",
    "d = 10\n",
    "N = 10000\n",
    "ads_selected=[]\n",
    "\n",
    "for i in range(0,N,1):\n",
    "    ad = 0\n",
    "    max_UCB = 0\n",
    "    for j in range(0,d):\n",
    "        if(num_of_slection[j] != 0):\n",
    "            avg_reward =  sums_of_rewards[j]/num_of_slection[j]\n",
    "            delta = math.sqrt(3/2 * math.log(i+1)/ num_of_slection[j])\n",
    "            UCB = avg_reward + delta\n",
    "        else:\n",
    "            UCB = 1e400 #force selection of the ad\n",
    "        if(UCB > max_UCB):\n",
    "            max_UCB =UCB\n",
    "            ad = j\n",
    "    ads_selected.append(ad)\n",
    "    num_of_slection[ad] += 1\n",
    "    sums_of_rewards[ad] += dataset.values[i,ad]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## 6.1 - Multi Armed Bandit Problem and Upper Confidence Bound\n",
    "\n",
    "Reinforcement Learning is a method to teach a machine to perform task by providing positive feedback for actions performed correctly. The Multi armed Bandit problem is the following:\n",
    "\n",
    "Let's consider a slot machine with a lever which we need to pull in order to play. Say there are a set of such machines under the assumption that each of these machine has a distribution that allows the machine to pick the numbers. We have 5 machines and possibily there are 5 distributions. And wee need to decide which of these slot machine is the best for us.\n",
    "\n",
    "Formally:\n",
    "\n",
    "1 - We have $d$ arms, say ads, that we display to users when they connect to a web page\n",
    "\n",
    "2-  Each user conncetion makes a 'round of game'\n",
    "\n",
    "3- at each round we display only one ad\n",
    "\n",
    "4- If the user clicks on the ad $\\rightarrow$ we get the reward 1 otherwise we get the reward 0\n",
    "\n",
    "5- Goal is to maximise the number of rewards\n",
    "\n",
    "Upper bound confidence works as follows:\n",
    "\n",
    "1- At each round $n$ for each ad $i$ there are two numbers associated: $N_i(n)$ the number of times the ad $i$ was selected up to round $n$, and $R_i(n)$ the sum of rewards up to round $n$ for ad $i$\n",
    "\n",
    "2 - we can compute then \n",
    "$$ <r_i(n)> = \\frac{R_i(n)}{N_i(n)} $$ \n",
    "the average reward and the confidence interval $\\Delta_i(n)$\n",
    "$$ \\Delta_i(n) = \\sqrt{ \\frac{3 \\log(n)}{2 N_i(n)} } $$\n",
    "\n",
    "3 - we select the $i$ that has the highest sum $<r_i(n)> + \\Delta_i(n)$\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}